{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Joins in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `SparkSession`. No need to create `SparkContext` as you automatically get it as part of the `SparkSession`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Exploring Joins\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Natural vs Regular Joins\n",
    "\n",
    "Two types of joins:\n",
    "1. `Natural Join`  \n",
    "    A Natural Join is where 2 tables are joined on the basis of all common columns.      \n",
    "    ie. `left.join(right, 'key')`\n",
    "\n",
    "2. `Regular Join`  \n",
    "    A Inner Join is where 2 tables are joined on the basis of common columns mentioned in the ON clause.\n",
    "    ie. `left.join(right, left[lkey] == right[rkey])`\n",
    "\n",
    "**Question:**\n",
    "    Is `rename`ing a `column` then doing a `natural join` better than doing an `inner join`? Is it just a style choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  data_id val_1\n",
       "0   1        1     a\n",
       "1   2        1     b\n",
       "2   2        2     c"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 'a'), \n",
    "        (2, 1, 'b'), \n",
    "        (2, 2, 'c'), \n",
    "    ], ['id', 'data_id', 'val_1']\n",
    ")\n",
    "\n",
    "df_1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id  val_2\n",
       "0        1        1     10\n",
       "1        2        2     20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 10), \n",
    "        (2, 2, 20), \n",
    "    ], ['shop_id', 'data_id', 'val_2']\n",
    ")\n",
    "\n",
    "df_2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Rename Key, then Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id val_1  data_id  val_2\n",
       "0        1        1     a        1     10\n",
       "1        2        1     b        2     20\n",
       "2        2        2     c        2     20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = df_1.withColumnRenamed('id', 'shop_id')\n",
    "\n",
    "df = df_3.join(df_2, 'shop_id')\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [shop_id#12L, data_id#1L, val_1#2, data_id#7L, val_2#8L]\n",
      "+- *(5) SortMergeJoin [shop_id#12L], [shop_id#6L], Inner\n",
      "   :- *(2) Sort [shop_id#12L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(shop_id#12L, 200)\n",
      "   :     +- *(1) Project [id#0L AS shop_id#12L, data_id#1L, val_1#2]\n",
      "   :        +- *(1) Filter isnotnull(id#0L)\n",
      "   :           +- Scan ExistingRDD[id#0L,data_id#1L,val_1#2]\n",
      "   +- *(4) Sort [shop_id#6L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(shop_id#6L, 200)\n",
      "         +- *(3) Filter isnotnull(shop_id#6L)\n",
      "            +- Scan ExistingRDD[shop_id#6L,data_id#7L,val_2#8L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* An extra `Project` was performed before the join due to the rename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Don't Rename, Regular Join, Drop Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id val_1  shop_id  data_id  val_2\n",
       "0        1     a        1        1     10\n",
       "1        1     b        2        2     20\n",
       "2        2     c        2        2     20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_condition = df_1['id'] == df_2['shop_id']\n",
    "\n",
    "df = df_1 \\\n",
    "    .join(df_2, join_condition) \\\n",
    "    .drop(df_1['id'])\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#1L, val_1#2, shop_id#6L, data_id#7L, val_2#8L]\n",
      "+- *(5) SortMergeJoin [id#0L], [shop_id#6L], Inner\n",
      "   :- *(2) Sort [id#0L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#0L, 200)\n",
      "   :     +- *(1) Filter isnotnull(id#0L)\n",
      "   :        +- Scan ExistingRDD[id#0L,data_id#1L,val_1#2]\n",
      "   +- *(4) Sort [shop_id#6L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(shop_id#6L, 200)\n",
      "         +- *(3) Filter isnotnull(shop_id#6L)\n",
      "            +- Scan ExistingRDD[shop_id#6L,data_id#7L,val_2#8L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* No `Project` was done before the join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "Option #1\n",
    "* Looks nicer and more elegant.\n",
    "* How does it perform?\n",
    "\n",
    "Option #2\n",
    "* There is one less project as expected without the `withColumnRenamed`.\n",
    "* But the join claus is a lot longer and ugly.\n",
    "\n",
    "**I personally like option #1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Filter Pushdown\n",
    "\n",
    "> `Filter pushdown` improves performance by reducing the amount of data shuffled during any dataframes transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id val_1\n",
       "0        1        1     a\n",
       "1        2        1     b\n",
       "2        2        2     c"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 'a'), \n",
    "        (2, 1, 'b'), \n",
    "        (2, 2, 'c'), \n",
    "    ], ['shop_id', 'data_id', 'val_1']\n",
    ")\n",
    "\n",
    "df_1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id  val_2\n",
       "0        1        1     10\n",
       "1        2        2     20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 1, 10), \n",
    "        (2, 2, 20), \n",
    "    ], ['shop_id', 'data_id', 'val_2']\n",
    ")\n",
    "\n",
    "df_2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #1: Join the data, then perform Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  shop_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_1 \\\n",
    "    .join(df_2.drop('shop_id'), 'data_id') \\\n",
    "    .filter(F.col('shop_id') == 1)\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#45L, shop_id#44L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [data_id#45L], [data_id#51L], Inner\n",
      "   :- *(2) Sort [data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(data_id#51L, 200)\n",
      "         +- *(3) Project [data_id#51L, val_2#52L]\n",
      "            +- *(3) Filter isnotnull(data_id#51L)\n",
      "               +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened:**\n",
    "\n",
    "* We can see that the filter is after the join and not pushed down. \n",
    "* This means all of the data is brough to the join.\n",
    "* Then the filter is done.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "We bring more data to the join and shuffle, **this is bad**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #2: Join on Filter Key, then Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>data_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  data_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_1 \\\n",
    "    .join(df_2, ['shop_id', 'data_id']) \\\n",
    "    .filter(F.col('shop_id') == 1)\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [shop_id#44L, data_id#45L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [shop_id#44L, data_id#45L], [shop_id#50L, data_id#51L], Inner\n",
      "   :- *(2) Sort [shop_id#44L ASC NULLS FIRST, data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(shop_id#44L, data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [shop_id#50L ASC NULLS FIRST, data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(shop_id#50L, data_id#51L, 200)\n",
      "         +- *(3) Filter (((shop_id#50L = 1) && isnotnull(data_id#51L)) && isnotnull(shop_id#50L))\n",
      "            +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened:**\n",
    "* The filter got pushed down.\n",
    "* Less data is brought to the join and shuffle.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "We bring less data to the join and shuffle, **this is good**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #3: Filter Left, then Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  shop_id val_1  val_2\n",
       "0        1        1     a     10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_1 \\\n",
    "    .filter(F.col('shop_id') == 1) \\\n",
    "    .join(df_2.drop('shop_id'), 'data_id')\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#45L, shop_id#44L, val_1#46, val_2#52L]\n",
      "+- *(5) SortMergeJoin [data_id#45L], [data_id#51L], Inner\n",
      "   :- *(2) Sort [data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [data_id#51L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(data_id#51L, 200)\n",
      "         +- *(3) Project [data_id#51L, val_2#52L]\n",
      "            +- *(3) Filter isnotnull(data_id#51L)\n",
      "               +- Scan ExistingRDD[shop_id#50L,data_id#51L,val_2#52L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened:**\n",
    "* This is exactly the same as case 1.\n",
    "\n",
    "**Results:**\n",
    "\n",
    "We bring less data to the join and shuffle, **this is bad**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #4: Filter Both, then Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>val_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_id  shop_id val_1  shop_id val_1\n",
       "0        1        1     a        1     a\n",
       "1        1        1     a        2     b"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_2 \\\n",
    "    .filter(F.col('shop_id') == 1) \\\n",
    "    .drop('shop_id')\n",
    "\n",
    "df = df_1 \\\n",
    "    .filter(F.col('shop_id') == 1) \\\n",
    "    .join(df_3, 'data_id')\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [data_id#45L, shop_id#44L, val_1#46, shop_id#12L, val_1#2]\n",
      "+- *(5) SortMergeJoin [data_id#45L], [data_id#1L], Inner\n",
      "   :- *(2) Sort [data_id#45L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(data_id#45L, 200)\n",
      "   :     +- *(1) Filter ((isnotnull(shop_id#44L) && (shop_id#44L = 1)) && isnotnull(data_id#45L))\n",
      "   :        +- Scan ExistingRDD[shop_id#44L,data_id#45L,val_1#46]\n",
      "   +- *(4) Sort [data_id#1L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(data_id#1L, 200)\n",
      "         +- *(3) Project [id#0L AS shop_id#12L, data_id#1L, val_1#2]\n",
      "            +- *(3) Filter isnotnull(data_id#1L)\n",
      "               +- Scan ExistingRDD[id#0L,data_id#1L,val_1#2]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "* We should always try to push the filter down as much as possible. \n",
    "* This means that there will be less data being shuffled and joined during the join. \n",
    "* This can be achieved with join in case #2 or #4.\n",
    "\n",
    "**Option #2** (Good)\n",
    "* When we `join`ed on `filter`ed on the key `shop_id` this caused a `filter-pushdown` which is good.\n",
    "* But this made us `sort` on 2 keys.\n",
    "\n",
    "**Option #4** (Better)\n",
    "* When we pre `filter` the `join`ing datasets, this caused a `filter-pushdown` which is good.\n",
    "* We only `join` on one key as well, which is good as we only sort on 1 key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Joins on Skewed Data\n",
    "\n",
    "A `skewed dataset` is defined by a dataset that has a class imbalance, this leads to poor or uncompletable spark jobs often getting `OOM` (out of memory) errors.\n",
    "\n",
    "When performing a `join` onto a `skewed dataset` it means that there exists a class imbalance on the `key`s on which the join is performed on. This results in a majority of the data falls onto one partition, which will take longer to complete than the other partitions.\n",
    "\n",
    "Some examples of this are:\n",
    "1. The keys consist mainly of `null` values which fall onto a single partition.\n",
    "2. There is a subset of keys that makeup the majority percentage of the keys which fall onto a single partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation 1: Null Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inital Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>card_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  card_id\n",
       "0   1      NaN\n",
       "1   2      NaN\n",
       "2   3      1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = spark.createDataFrame([\n",
    "    (1, None), \n",
    "    (2, None), \n",
    "    (3, 1),\n",
    "], [\"id\", \"card_id\"])\n",
    "\n",
    "customers.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>rick</td>\n",
       "      <td>roll</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>bob</td>\n",
       "      <td>brown</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id first_name last_name  age\n",
       "0        1       john       doe   21\n",
       "1        2       rick      roll   10\n",
       "2        3        bob     brown    2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards = spark.createDataFrame([\n",
    "    (1, \"john\", \"doe\", 21), \n",
    "    (2, \"rick\", \"roll\", 10), \n",
    "    (3, \"bob\", \"brown\", 2)\n",
    "], [\"card_id\", \"first_name\", \"last_name\", \"age\"])\n",
    "\n",
    "cards.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #1: Join Regularly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_id  id first_name last_name   age\n",
       "0      NaN   1       None      None   NaN\n",
       "1      NaN   2       None      None   NaN\n",
       "2      1.0   3       john       doe  21.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = customers.join(cards, \"card_id\", \"left\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [card_id#85L, id#84L, first_name#89, last_name#90, age#91L]\n",
      "+- SortMergeJoin [card_id#85L], [card_id#88L], LeftOuter\n",
      "   :- *(1) Sort [card_id#85L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(card_id#85L, 200)\n",
      "   :     +- Scan ExistingRDD[id#84L,card_id#85L]\n",
      "   +- *(2) Sort [card_id#88L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(card_id#88L, 200)\n",
      "         +- Scan ExistingRDD[card_id#88L,first_name#89,last_name#90,age#91L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* Rows that didn't join up were brought to the join.\n",
    "* They get `Null` values for the right side columns.\n",
    "\n",
    "**Results**:\n",
    "* We brought more data to the join than we had to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #2: Filter Null Keys First, then Join, then Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  card_id first_name last_name   age\n",
       "0   1      NaN       None      None   NaN\n",
       "1   2      NaN       None      None   NaN\n",
       "2   3      1.0       john       doe  21.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def null_skew_helper(left, right, key):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "        1. Filter out the null rows.\n",
    "        2. Create the columns you would get from the join.\n",
    "        3. Join the tables.\n",
    "        4. Union the null rows to joined table.\n",
    "    \"\"\"\n",
    "    df1 = left.where(F.col(key).isNull())\n",
    "    for f in right.schema.fields:\n",
    "            df1 = df1.withColumn(f.name, F.lit(None).cast(f.dataType))\n",
    "    \n",
    "    df2 = left.where(F.col(key).isNotNull())\n",
    "    df2 = df2.join(right, key, \"left\")\n",
    "    \n",
    "    return df1.union(df2.select(df1.columns))\n",
    "    \n",
    "    \n",
    "df = null_skew_helper(customers, cards, \"card_id\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Union\n",
      ":- *(1) Project [id#84L, null AS card_id#102L, null AS first_name#105, null AS last_name#109, null AS age#114L]\n",
      ":  +- *(1) Filter isnull(card_id#85L)\n",
      ":     +- Scan ExistingRDD[id#84L,card_id#85L]\n",
      "+- *(5) Project [id#84L, card_id#85L, first_name#89, last_name#90, age#91L]\n",
      "   +- SortMergeJoin [card_id#85L], [card_id#88L], LeftOuter\n",
      "      :- *(3) Sort [card_id#85L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(card_id#85L, 200)\n",
      "      :     +- *(2) Filter isnotnull(card_id#85L)\n",
      "      :        +- Scan ExistingRDD[id#84L,card_id#85L]\n",
      "      +- *(4) Sort [card_id#88L ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(card_id#88L, 200)\n",
      "            +- Scan ExistingRDD[card_id#88L,first_name#89,last_name#90,age#91L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* We filtered all the rows out before the join.\n",
    "* We did the join with less data.\n",
    "* We read the table again and got the null rows.\n",
    "* Unioned with the joined results.\n",
    "\n",
    "**Results**:\n",
    "* We brought less data to the join.\n",
    "* But we read the data twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #3: Cache Table, Filter Null Keys First, then Join, then Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_skew_helper(left, right, key):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "        1. Cache table.\n",
    "        2. Filter out the null rows.\n",
    "        3. Create the columns you would get from the join.\n",
    "        4. Join the tables.\n",
    "        5. Union the null rows to joined table.\n",
    "    \"\"\"\n",
    "    left = left.cache()\n",
    "    \n",
    "    df1 = left.where(F.col(key).isNull())\n",
    "    for f in right.schema.fields:\n",
    "            df1 = df1.withColumn(f.name, F.lit(None).cast(f.dataType))\n",
    "    \n",
    "    df2 = left.where(F.col(key).isNotNull())\n",
    "    df2 = df2.join(right, key, \"left\")\n",
    "    \n",
    "    return df1.union(df2.select(df1.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>john</td>\n",
       "      <td>doe</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  card_id first_name last_name   age\n",
       "0   1      NaN       None      None   NaN\n",
       "1   2      NaN       None      None   NaN\n",
       "2   3      1.0       john       doe  21.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = null_skew_helper(customers, cards, \"card_id\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Union\n",
      ":- *(1) Project [id#84L, null AS card_id#147L, null AS first_name#150, null AS last_name#154, null AS age#159L]\n",
      ":  +- *(1) Filter isnull(card_id#85L)\n",
      ":     +- *(1) InMemoryTableScan [card_id#85L, id#84L], [isnull(card_id#85L)]\n",
      ":           +- InMemoryRelation [id#84L, card_id#85L], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      ":                 +- Scan ExistingRDD[id#84L,card_id#85L]\n",
      "+- *(5) Project [id#84L, card_id#85L, first_name#89, last_name#90, age#91L]\n",
      "   +- SortMergeJoin [card_id#85L], [card_id#88L], LeftOuter\n",
      "      :- *(3) Sort [card_id#85L ASC NULLS FIRST], false, 0\n",
      "      :  +- Exchange hashpartitioning(card_id#85L, 200)\n",
      "      :     +- *(2) Filter isnotnull(card_id#85L)\n",
      "      :        +- *(2) InMemoryTableScan [id#84L, card_id#85L], [isnotnull(card_id#85L)]\n",
      "      :              +- InMemoryRelation [id#84L, card_id#85L], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "      :                    +- Scan ExistingRDD[id#84L,card_id#85L]\n",
      "      +- *(4) Sort [card_id#88L ASC NULLS FIRST], false, 0\n",
      "         +- Exchange hashpartitioning(card_id#88L, 200)\n",
      "            +- Scan ExistingRDD[card_id#88L,first_name#89,last_name#90,age#91L]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* Similar to option #2, but we did a `InMemoryTableScan` instead of a read of the data.\n",
    "\n",
    "**Results**:\n",
    "* We brought less data to the join.\n",
    "* We did 1 less read, but we used more memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "As always there is pros and cons.\n",
    "\n",
    "Pros:\n",
    "* Ideally you want to bring less data to a join. \n",
    "* This is unneeded data and in most cases causes a spark job to fail. \n",
    "* This is due to the fact that all the null key rows will go onto one partition.\n",
    "\n",
    "Cons:\n",
    "* There will either be one extra read of data or more memory used.\n",
    "\n",
    "All to say:\n",
    "1. It's definitely better to bring less data to a join, so performing an union and filter of the `null keys` before the join is definitely suggested.\n",
    "2. This will result in an extra read of data or memory usage.\n",
    "3. Decide if you can afford the extra read vs memory usage and `cache` the table before the filter.\n",
    "\n",
    "Always check the spread of values for the `join key`, to detect if there's any skew and any optimizations you can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation 2: Data Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inital Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id first_name\n",
       "0            1       John\n",
       "1            2        Bob"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers = spark.createDataFrame([\n",
    "    (1, \"John\"), \n",
    "    (2, \"Bob\"),\n",
    "], [\"customer_id\", \"first_name\"])\n",
    "\n",
    "customers.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>order #94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>2</td>\n",
       "      <td>order #95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>order #96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>order #97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "      <td>order #98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>order #99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  customer_id order_name\n",
       "94  94            1  order #94\n",
       "95  95            2  order #95\n",
       "96  96            2  order #96\n",
       "97  97            2  order #97\n",
       "98  98            2  order #98\n",
       "99  99            2  order #99"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = spark.createDataFrame([\n",
    "    (i, 1 if i < 95 else 2, \"order #{}\".format(i)) for i in range(100) \n",
    "], [\"id\", \"customer_id\", \"order_name\"])\n",
    "\n",
    "orders.toPandas().tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Regular Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>id</th>\n",
       "      <th>order_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>90</td>\n",
       "      <td>order #90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>91</td>\n",
       "      <td>order #91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>92</td>\n",
       "      <td>order #92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>93</td>\n",
       "      <td>order #93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>94</td>\n",
       "      <td>order #94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>95</td>\n",
       "      <td>order #95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>96</td>\n",
       "      <td>order #96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>97</td>\n",
       "      <td>order #97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>98</td>\n",
       "      <td>order #98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>99</td>\n",
       "      <td>order #99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id first_name  id order_name\n",
       "90            1       John  90  order #90\n",
       "91            1       John  91  order #91\n",
       "92            1       John  92  order #92\n",
       "93            1       John  93  order #93\n",
       "94            1       John  94  order #94\n",
       "95            2        Bob  95  order #95\n",
       "96            2        Bob  96  order #96\n",
       "97            2        Bob  97  order #97\n",
       "98            2        Bob  98  order #98\n",
       "99            2        Bob  99  order #99"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = customers.join(orders, \"customer_id\")\n",
    "\n",
    "df.toPandas().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [customer_id#201L, first_name#202, id#205L, order_name#207]\n",
      "+- *(5) SortMergeJoin [customer_id#201L], [customer_id#206L], Inner\n",
      "   :- *(2) Sort [customer_id#201L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(customer_id#201L, 200)\n",
      "   :     +- *(1) Filter isnotnull(customer_id#201L)\n",
      "   :        +- Scan ExistingRDD[customer_id#201L,first_name#202]\n",
      "   +- *(4) Sort [customer_id#206L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(customer_id#206L, 200)\n",
      "         +- *(3) Filter isnotnull(customer_id#206L)\n",
      "            +- Scan ExistingRDD[id#205L,customer_id#206L,order_name#207]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* We want to find what `order`s each `customer` made, so we will be `join`ing the `customer`s table to the `order`s table.\n",
    "* When performing the join, we perform a `hashpartitioning` on `customer_id`.\n",
    "* From our data creation, this means 95% of the data landed onto a single partition. \n",
    "\n",
    "**Results**:\n",
    "* Similar to the `Null Skew` case, this means that single task/partition will take a lot longer than the others, and most likely erroring out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Salt the key, then Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_skew_helper(left, right, key, number_of_partitions, how=\"inner\"):\n",
    "    salt_value = F.lit(F.rand() * number_of_partitions % number_of_partitions).cast('int')\n",
    "    left = left.withColumn(\"salt\", salt_value)\n",
    "    \n",
    "    salt_col = F.explode(F.array([F.lit(i) for i in range(number_of_partitions)])).alias(\"salt\")\n",
    "    right = right.select(\"*\",  salt_col)\n",
    "\n",
    "    return left.join(right, [key, \"salt\"], how).drop(\"salt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_name</th>\n",
       "      <th>salt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>order #0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>order #1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>order #2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>order #3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>order #4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  customer_id order_name  salt\n",
       "0   0            1   order #0     1\n",
       "1   1            1   order #1     1\n",
       "2   2            1   order #2     1\n",
       "3   3            1   order #3     1\n",
       "4   4            1   order #4     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = orders\n",
    "\n",
    "salt_value = F.lit(F.rand() * 2 % 2).cast('int')    \n",
    "left.withColumn(\"salt\", salt_value).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>salt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id first_name  salt\n",
       "0            1       John     0\n",
       "1            1       John     1\n",
       "2            2        Bob     0\n",
       "3            2        Bob     1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right = customers\n",
    "\n",
    "salt_col = F.explode(F.array([F.lit(i) for i in range(2)])).alias(\"salt\")\n",
    "right.select(\"*\",  salt_col).toPandas().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>id</th>\n",
       "      <th>order_name</th>\n",
       "      <th>first_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>order #90</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>order #91</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>order #92</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>order #93</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>order #94</td>\n",
       "      <td>John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>order #95</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>order #96</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>order #97</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>98</td>\n",
       "      <td>order #98</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>order #99</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  id order_name first_name\n",
       "90            1  90  order #90       John\n",
       "91            1  91  order #91       John\n",
       "92            1  92  order #92       John\n",
       "93            1  93  order #93       John\n",
       "94            1  94  order #94       John\n",
       "95            2  95  order #95        Bob\n",
       "96            2  96  order #96        Bob\n",
       "97            2  97  order #97        Bob\n",
       "98            2  98  order #98        Bob\n",
       "99            2  99  order #99        Bob"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_skew_helper(orders, customers, \"customer_id\", 5)\n",
    "\n",
    "df.orderBy('id').toPandas().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [customer_id#206L, id#205L, order_name#207, first_name#202]\n",
      "+- *(5) SortMergeJoin [customer_id#206L, salt#225], [customer_id#201L, salt#231], Inner\n",
      "   :- *(2) Sort [customer_id#206L ASC NULLS FIRST, salt#225 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(customer_id#206L, salt#225, 200)\n",
      "   :     +- *(1) Filter (isnotnull(customer_id#206L) && isnotnull(salt#225))\n",
      "   :        +- *(1) Project [id#205L, customer_id#206L, order_name#207, cast(((rand(454193232799453665) * 5.0) % 5.0) as int) AS salt#225]\n",
      "   :           +- Scan ExistingRDD[id#205L,customer_id#206L,order_name#207]\n",
      "   +- *(4) Sort [customer_id#201L ASC NULLS FIRST, salt#231 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(customer_id#201L, salt#231, 200)\n",
      "         +- Generate explode([0,1,2,3,4]), [customer_id#201L, first_name#202], false, [salt#231]\n",
      "            +- *(3) Filter isnotnull(customer_id#201L)\n",
      "               +- Scan ExistingRDD[customer_id#201L,first_name#202]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What Happened**:\n",
    "* We create a new `salt` column for both datasets.\n",
    "* On one of the dataset we duplicate the data so we have a row for each `salt` value.\n",
    "* When performing the join, we perform a `hashpartitioning` on `[customer_id, salt]`.\n",
    "\n",
    "**Results**:\n",
    "* When we produce a row per `salt` value, we have essentially duplicated `(num_partitions - 1) * N` rows.\n",
    "* This allows us to spread the data across more partitions as you can see from `hashpartitioning(customer_id, salt)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "\n",
    "All to say:\n",
    "* Again we will sacrifice more resources in order to get a performance gain or a successful run.\n",
    "* By `salt`ing our keys, the `skewed` dataset gets divided into smaller partitions. Thus removing the skew.\n",
    "* We produced more data by creating `(num_partitions - 1) * N` more data for the right side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 4: Range Join Conditions [TODO]\n",
    "\n",
    "> A naive approach (just specifying this as the range condition) would result in a full cartesian product and a filter that enforces the condition (tested using Spark 2.0). This has a horrible effect on performance, especially if DataFrames are more than a few hundred thousands records.\n",
    "\n",
    "source: http://zachmoshe.com/2016/09/26/efficient-range-joins-with-spark.html\n",
    "\n",
    "> The source of the problem is pretty simple. When you execute join and join condition is not equality based the only thing that Spark can do right now is expand it to Cartesian product followed by filter what is pretty much what happens inside `BroadcastNestedLoopJoin`\n",
    "\n",
    "source: https://stackoverflow.com/questions/37953830/spark-sql-performance-join-on-value-between-min-and-max?answertab=active#tab-top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipstart</th>\n",
       "      <th>ipend</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>foo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipstart  ipend  loc\n",
       "0        1     10  foo\n",
       "1       11     36  bar\n",
       "2       37     59  baz"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_loc_table = spark.createDataFrame([\n",
    "    (1, 10, \"foo\"), \n",
    "    (11, 36, \"bar\"), \n",
    "    (37, 59, \"baz\"),\n",
    "], [\"ipstart\", \"ipend\", \"loc\"])\n",
    "\n",
    "geo_loc_table.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  inet\n",
       "0   1    11\n",
       "1   2    38\n",
       "2   3    50"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_table = spark.createDataFrame([\n",
    "    (1, 11), \n",
    "    (2, 38), \n",
    "    (3, 50),\n",
    "],[\"id\", \"inet\"])\n",
    "\n",
    "records_table.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>inet</th>\n",
       "      <th>ipstart</th>\n",
       "      <th>ipend</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>37</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  inet  ipstart  ipend  loc\n",
       "0   1    11       11     36  bar\n",
       "1   2    38       37     59  baz\n",
       "2   3    50       37     59  baz"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_condition = [\n",
    "    records_table['inet'] >= geo_loc_table['ipstart'],\n",
    "    records_table['inet'] <= geo_loc_table['ipend'],\n",
    "]\n",
    "\n",
    "df = records_table.join(geo_loc_table, join_condition, \"left\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "BroadcastNestedLoopJoin BuildRight, LeftOuter, ((inet#252L >= ipstart#245L) && (inet#252L <= ipend#246L))\n",
      ":- Scan ExistingRDD[id#251L,inet#252L]\n",
      "+- BroadcastExchange IdentityBroadcastMode\n",
      "   +- Scan ExistingRDD[ipstart#245L,ipend#246L,loc#247]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ipstart</th>\n",
       "      <th>id</th>\n",
       "      <th>inet</th>\n",
       "      <th>ipend</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>baz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>bar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ipstart  id  inet  ipend  loc\n",
       "0       37   2    38     59  baz\n",
       "1       37   3    50     59  baz\n",
       "2       11   1    11     36  bar"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bisect import bisect_right\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "geo_start_bd = spark.sparkContext.broadcast(map(lambda x: x.ipstart, geo_loc_table\n",
    "    .select(\"ipstart\")\n",
    "    .orderBy(\"ipstart\")\n",
    "    .collect()\n",
    "))\n",
    "\n",
    "def find_le(x):\n",
    "    'Find rightmost value less than or equal to x'\n",
    "    i = bisect_right(geo_start_bd.value, x)\n",
    "    if i:\n",
    "        return geo_start_bd.value[i-1]\n",
    "    return None\n",
    "\n",
    "records_table_with_ipstart = records_table.withColumn(\n",
    "    \"ipstart\", udf(find_le, LongType())(\"inet\")\n",
    ")\n",
    "\n",
    "df = records_table_with_ipstart.join(geo_loc_table, [\"ipstart\"], \"left\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) Project [ipstart#272L, id#251L, inet#252L, ipend#246L, loc#247]\n",
      "+- SortMergeJoin [ipstart#272L], [ipstart#245L], LeftOuter\n",
      "   :- *(2) Sort [ipstart#272L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(ipstart#272L, 200)\n",
      "   :     +- *(1) Project [id#251L, inet#252L, pythonUDF0#281L AS ipstart#272L]\n",
      "   :        +- BatchEvalPython [find_le(inet#252L)], [id#251L, inet#252L, pythonUDF0#281L]\n",
      "   :           +- Scan ExistingRDD[id#251L,inet#252L]\n",
      "   +- *(3) Sort [ipstart#245L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(ipstart#245L, 200)\n",
      "         +- Scan ExistingRDD[ipstart#245L,ipend#246L,loc#247]\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
